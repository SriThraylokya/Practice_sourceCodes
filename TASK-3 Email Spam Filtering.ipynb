{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyONQQM7dThCdMnxsBiyDmao"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from sklearn.feature_extraction.text import CountVectorizer\n","from sklearn.naive_bayes import MultinomialNB,GaussianNB\n","from sklearn.metrics import confusion_matrix,classification_report\n","import matplotlib.pyplot as plt\n","\n","# Load the data\n","data = pd.read_csv('/content/spam_ham_dataset.csv')"],"metadata":{"id":"UXhZX7bSeDxY","executionInfo":{"status":"ok","timestamp":1712072537704,"user_tz":-330,"elapsed":396,"user":{"displayName":"S Sri Thraylokya","userId":"14169869104563715003"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["# Split the data into training and testing sets\n","X_train, X_test, y_train, y_test = train_test_split(data['text'], data['label'], test_size=0.2, random_state=42)\n","\n","# Vectorize the text data using CountVectorizer,CountVectorizer takes a corpus of text and converts it into a\n","#numerical representation that can be used as input to machine learning models. It works by first tokenizing\n","# the text into words or n-grams, and then counting the frequency of each word or n-gram in each document.\n","vectorizer = CountVectorizer()\n","X_train_vectorized = vectorizer.fit_transform(X_train)\n","#print(type(X_train_vectorized))\n","# Train the MultinomialNB Naive Bayes classifier,This classifier is suitable for discrete data, such as word counts,\n","#it calculates the probability of each class given the word frequency.\n","clf = MultinomialNB()\n","clf.fit(X_train_vectorized, y_train)\n","\n","# Evaluate the performance of the classifier\n","X_test_vectorized = vectorizer.transform(X_test)\n","y_pred=clf.predict(X_test_vectorized)\n","#print(type(y_pred),type(y_test.values))\n","#y_pred=y_pred.reshape(-1,1)"],"metadata":{"id":"rRAYcjYoehSv","executionInfo":{"status":"ok","timestamp":1712072567131,"user_tz":-330,"elapsed":3228,"user":{"displayName":"S Sri Thraylokya","userId":"14169869104563715003"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["#Printing the confusion matrix\n","cm=confusion_matrix(y_pred,y_test)\n","print(cm)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pM-uwKDKemiX","executionInfo":{"status":"ok","timestamp":1712072586485,"user_tz":-330,"elapsed":409,"user":{"displayName":"S Sri Thraylokya","userId":"14169869104563715003"}},"outputId":"4a301636-5905-4890-b56f-ce2dc1619c8a"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["[[729  16]\n"," [ 13 277]]\n"]}]},{"cell_type":"code","source":["#Accuracy\n","a1=cm.shape\n","c1=0\n","w1=0\n","for i in range (a1[0]):\n","    for j in range(a1[1]):\n","        if i==j:\n","            c1+=cm[i,j]\n","        else:\n","            w1+=cm[i,j]\n","print(\"Correct classification \",c1,\"Incorrect classification \",w1)\n","print(\"Accuracy of the classification is:\",(c1/(c1+w1))*100)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"v-DNEnEaeqlL","executionInfo":{"status":"ok","timestamp":1712072603401,"user_tz":-330,"elapsed":6,"user":{"displayName":"S Sri Thraylokya","userId":"14169869104563715003"}},"outputId":"0f87f3d0-05c7-429b-a208-8c683f9e6b48"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Correct classification  1006 Incorrect classification  29\n","Accuracy of the classification is: 97.19806763285024\n"]}]},{"cell_type":"code","source":["#Evaluating the model using F1 score, Precision, recall\n","print(classification_report(y_pred,y_test))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DFT-uP4TetgS","executionInfo":{"status":"ok","timestamp":1712072615184,"user_tz":-330,"elapsed":532,"user":{"displayName":"S Sri Thraylokya","userId":"14169869104563715003"}},"outputId":"0a99b73b-6180-4a42-c2e2-ba5af48f86dc"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","         ham       0.98      0.98      0.98       745\n","        spam       0.95      0.96      0.95       290\n","\n","    accuracy                           0.97      1035\n","   macro avg       0.96      0.97      0.97      1035\n","weighted avg       0.97      0.97      0.97      1035\n","\n"]}]}]}